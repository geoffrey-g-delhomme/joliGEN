{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "\n",
    "- generate images from train dataset\n",
    "- generate images from test dataset\n",
    "- generate images from out of input distribution (no real airports)\n",
    "- generate images for all train & test dataset (+ out of distribution ?)\n",
    "- retrain yolo-nas and compare results\n",
    "\n",
    "WITHOUT / PARTIALLY / WITH\n",
    "mAP ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geoffrey.g.delhomme/miniconda3/envs/joligen/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/geoffrey.g.delhomme/miniconda3/envs/joligen/lib/python3.10/site-packages/mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_5m_224 in registry with mobile_sam.modeling.tiny_vit_sam.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/home/geoffrey.g.delhomme/miniconda3/envs/joligen/lib/python3.10/site-packages/mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_11m_224 in registry with mobile_sam.modeling.tiny_vit_sam.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/home/geoffrey.g.delhomme/miniconda3/envs/joligen/lib/python3.10/site-packages/mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_21m_224 in registry with mobile_sam.modeling.tiny_vit_sam.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/home/geoffrey.g.delhomme/miniconda3/envs/joligen/lib/python3.10/site-packages/mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_21m_384 in registry with mobile_sam.modeling.tiny_vit_sam.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/home/geoffrey.g.delhomme/miniconda3/envs/joligen/lib/python3.10/site-packages/mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_21m_512 in registry with mobile_sam.modeling.tiny_vit_sam.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from options.train_options import TrainOptions\n",
    "from models import gan_networks\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "IMAGE_DIRPATH = \"../tmp/samples\"\n",
    "DESTINATION_DIRPATH = \"../tmp/output-low-latest\"\n",
    "# IMAGE_DIRPATH = \"/mnt/data1/user_cache/geoffrey.g.delhomme/data/2023_12/augmented/coco-1024x750/train/images\"\n",
    "# DESTINATION_DIRPATH = \"/mnt/data1/user_cache/geoffrey.g.delhomme/data/2023_12/augmented/coco-1024x750/train/images\"\n",
    "if IMAGE_DIRPATH is not None:\n",
    "    IMAGE_FILEPATHS = [f.as_posix() for f in Path(IMAGE_DIRPATH).iterdir() if f.suffix in ['.png', '.jpg', '.jpeg']]\n",
    "# MODEL_FILEPATH = \"/home/geoffrey.g.delhomme/projects/joliGEN/checkpoints/synthetic2real_mask_online_bdd100k/latest_net_G_A.pth\"\n",
    "# MODEL_FILEPATH = \"/home/geoffrey.g.delhomme/projects/joliGEN/checkpoints/synthetic2real_mask_online/5_net_G_A.pth\"\n",
    "# MODEL_FILEPATH = \"/home/geoffrey.g.delhomme/projects/joliGEN/checkpoints/synthetic2real_mask_online/latest_net_G_A.pth\"\n",
    "# CONFIG_FILEPATH = \"/home/geoffrey.g.delhomme/projects/joliGEN/examples/example_gan_synthetic2real_mask_online.json\"\n",
    "# MODEL_FILEPATH = \"/home/geoffrey.g.delhomme/projects/joliGEN/checkpoints/synthetic2real_mask_online/latest_net_G_A.pth\"\n",
    "# CONFIG_FILEPATH = \"/home/geoffrey.g.delhomme/projects/joliGEN/examples/example_gan_synthetic2real_mask_online.json\"\n",
    "MODEL_FILEPATH = \"/home/geoffrey.g.delhomme/projects/joliGEN/checkpoints/synthetic2real_mask/latest_net_G_A.pth\"\n",
    "CONFIG_FILEPATH = \"/home/geoffrey.g.delhomme/projects/joliGEN/checkpoints/synthetic2real_mask/train_config-low.json\"\n",
    "IMAGE_WIDTH = 1024\n",
    "IMAGE_HEIGHT = 752\n",
    "GPUID = None # None: cpu else gpu id\n",
    "CONCAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "initialize network with normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [01:19<00:00,  2.10s/it]\n"
     ]
    }
   ],
   "source": [
    "cpu = GPUID is None\n",
    "gpuid = GPUID\n",
    "\n",
    "def get_z_random(batch_size=1, nz=8, random_type=\"gauss\"):\n",
    "    if random_type == \"uni\":\n",
    "        z = torch.rand(batch_size, nz) * 2.0 - 1.0\n",
    "    elif random_type == \"gauss\":\n",
    "        z = torch.randn(batch_size, nz)\n",
    "    return z.detach()\n",
    "\n",
    "# load model\n",
    "with open(CONFIG_FILEPATH, 'r') as f:\n",
    "    config = json.load(f)\n",
    "opt = TrainOptions().parse_json(config, set_device=False)\n",
    "if opt.model_multimodal:\n",
    "    opt.model_input_nc += opt.train_mm_nz\n",
    "opt.jg_dir = Path('..').resolve().as_posix()\n",
    "if not cpu:\n",
    "    device = torch.device(\"cuda:\" + str(gpuid))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "model = gan_networks.define_G(**vars(opt))\n",
    "model.eval()\n",
    "model.load_state_dict(\n",
    "    torch.load(MODEL_FILEPATH, map_location=device)\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# preprocess\n",
    "tranlist = [\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "]\n",
    "tran = transforms.Compose(tranlist)\n",
    "# TODO: parallelize with pools & gpus\n",
    "for image_filepath in tqdm(IMAGE_FILEPATHS):\n",
    "    image_filepath = Path(image_filepath)\n",
    "    # skip if name starts with 'r'\n",
    "    if image_filepath.name[0] == 'r':\n",
    "        continue\n",
    "    # copy image with prefix 'raw-'\n",
    "    raw_image_filepath = image_filepath.parent / (\"raw-\"+image_filepath.name)\n",
    "    if not raw_image_filepath.exists():\n",
    "        shutil.copy(image_filepath.as_posix(), raw_image_filepath.as_posix())\n",
    "    # load image\n",
    "    img_orig = cv2.imread(raw_image_filepath.as_posix())\n",
    "    img = cv2.cvtColor(img_orig.copy(), cv2.COLOR_BGR2RGB)\n",
    "    orig_height, orig_width, _ = img.shape\n",
    "    img = cv2.resize(img, (IMAGE_WIDTH, IMAGE_HEIGHT), interpolation=cv2.INTER_CUBIC)\n",
    "    # preprocess\n",
    "    img_tensor = tran(img).to(device)\n",
    "\n",
    "    if opt.model_multimodal:\n",
    "        z_random = get_z_random(batch_size=1, nz=opt.train_mm_nz)\n",
    "        z_random = z_random.to(device)\n",
    "        # print('z_random shape=', self.z_random.shape)\n",
    "        z_real = z_random.view(z_random.size(0), z_random.size(1), 1, 1).expand(\n",
    "            z_random.size(0),\n",
    "            z_random.size(1),\n",
    "            img_tensor.size(1),\n",
    "            img_tensor.size(2),\n",
    "        )\n",
    "        img_tensor = torch.cat([img_tensor.unsqueeze(0), z_real], 1)\n",
    "    else:\n",
    "        img_tensor = img_tensor.unsqueeze(0)\n",
    "\n",
    "    # run through model\n",
    "    out_tensor = model(img_tensor)[0].detach()\n",
    "\n",
    "    # post-processing\n",
    "    out_img = out_tensor.data.cpu().float().numpy()\n",
    "    out_img = (np.transpose(out_img, (1, 2, 0)) + 1) / 2.0 * 255.0\n",
    "    # print(out_img)\n",
    "    out_img = cv2.cvtColor(out_img, cv2.COLOR_RGB2BGR)\n",
    "    out_img = cv2.resize(out_img, (orig_width, orig_height), interpolation=cv2.INTER_CUBIC)\n",
    "    if CONCAT:\n",
    "        out_img = np.concatenate((img_orig, out_img), axis=1)\n",
    "    out_image_filepath = Path(DESTINATION_DIRPATH) / image_filepath.name\n",
    "    out_image_filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "    cv2.imwrite(out_image_filepath.as_posix(), out_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joligen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
