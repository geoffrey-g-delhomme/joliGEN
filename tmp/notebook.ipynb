{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "\n",
    "- generate images from train dataset\n",
    "- generate images from test dataset\n",
    "- generate images from out of input distribution (no real airports)\n",
    "- generate images for all train & test dataset (+ out of distribution ?)\n",
    "- retrain yolo-nas and compare results\n",
    "\n",
    "WITHOUT / PARTIALLY / WITH\n",
    "mAP ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geoffrey.g.delhomme/miniconda3/envs/joligen/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/geoffrey.g.delhomme/miniconda3/envs/joligen/lib/python3.10/site-packages/mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_5m_224 in registry with mobile_sam.modeling.tiny_vit_sam.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/home/geoffrey.g.delhomme/miniconda3/envs/joligen/lib/python3.10/site-packages/mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_11m_224 in registry with mobile_sam.modeling.tiny_vit_sam.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/home/geoffrey.g.delhomme/miniconda3/envs/joligen/lib/python3.10/site-packages/mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_21m_224 in registry with mobile_sam.modeling.tiny_vit_sam.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/home/geoffrey.g.delhomme/miniconda3/envs/joligen/lib/python3.10/site-packages/mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_21m_384 in registry with mobile_sam.modeling.tiny_vit_sam.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/home/geoffrey.g.delhomme/miniconda3/envs/joligen/lib/python3.10/site-packages/mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_21m_512 in registry with mobile_sam.modeling.tiny_vit_sam.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from options.train_options import TrainOptions\n",
    "from models import gan_networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "IMAGE_DIRPATH = \"../tmp/samples\"\n",
    "DESTINATION_DIRPATH = \"../tmp/output\"\n",
    "# IMAGE_DIRPATH = \"/mnt/data1/user_cache/geoffrey.g.delhomme/data/2023_12/coco-1024x750-augmented/train/images_origin\"\n",
    "# DESTINATION_DIRPATH = \"/mnt/data1/user_cache/geoffrey.g.delhomme/data/2023_12/coco-1024x750-augmented/train/images\"\n",
    "if IMAGE_DIRPATH is not None:\n",
    "    IMAGE_FILEPATHS = [f.as_posix() for f in Path(IMAGE_DIRPATH).iterdir() if f.suffix in ['.png', '.jpg', '.jpeg']]\n",
    "MODEL_FILEPATH = \"/home/geoffrey.g.delhomme/projects/joliGEN/checkpoints/synthetic2real_mask_online/20_net_G_A.pth\"\n",
    "# MODEL_FILEPATH = \"/home/geoffrey.g.delhomme/projects/joliGEN/checkpoints/synthetic2real_mask_online/39_net_G_A.pth\"\n",
    "CONFIG_FILEPATH = \"/home/geoffrey.g.delhomme/projects/joliGEN/examples/example_gan_synthetic2real_mask_online.json\"\n",
    "IMAGE_WIDTH = 1024\n",
    "IMAGE_HEIGHT = 752\n",
    "GPUID = 0 # None: cpu else gpu id\n",
    "CONCAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "initialize network with normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:02<00:00,  2.98it/s]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cpu = GPUID is None\n",
    "gpuid = GPUID\n",
    "\n",
    "def get_z_random(batch_size=1, nz=8, random_type=\"gauss\"):\n",
    "    if random_type == \"uni\":\n",
    "        z = torch.rand(batch_size, nz) * 2.0 - 1.0\n",
    "    elif random_type == \"gauss\":\n",
    "        z = torch.randn(batch_size, nz)\n",
    "    return z.detach()\n",
    "\n",
    "# load model\n",
    "with open(CONFIG_FILEPATH, 'r') as f:\n",
    "    config = json.load(f)\n",
    "opt = TrainOptions().parse_json(config, set_device=False)\n",
    "if opt.model_multimodal:\n",
    "    opt.model_input_nc += opt.train_mm_nz\n",
    "opt.jg_dir = Path('..').resolve().as_posix()\n",
    "if not cpu:\n",
    "    device = torch.device(\"cuda:\" + str(gpuid))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "model = gan_networks.define_G(**vars(opt))\n",
    "model.eval()\n",
    "model.load_state_dict(\n",
    "    torch.load(MODEL_FILEPATH, map_location=device)\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# preprocess\n",
    "tranlist = [\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "]\n",
    "tran = transforms.Compose(tranlist)\n",
    "for image_filepath in tqdm(IMAGE_FILEPATHS):\n",
    "    image_filepath = Path(image_filepath)\n",
    "    # load image\n",
    "    img_orig = cv2.imread(image_filepath.as_posix())\n",
    "    img = cv2.cvtColor(img_orig.copy(), cv2.COLOR_BGR2RGB)\n",
    "    orig_height, orig_width, _ = img.shape\n",
    "    img = cv2.resize(img, (IMAGE_WIDTH, IMAGE_HEIGHT), interpolation=cv2.INTER_CUBIC)\n",
    "    # preprocess\n",
    "    img_tensor = tran(img).to(device)\n",
    "\n",
    "    if opt.model_multimodal:\n",
    "        z_random = get_z_random(batch_size=1, nz=opt.train_mm_nz)\n",
    "        z_random = z_random.to(device)\n",
    "        # print('z_random shape=', self.z_random.shape)\n",
    "        z_real = z_random.view(z_random.size(0), z_random.size(1), 1, 1).expand(\n",
    "            z_random.size(0),\n",
    "            z_random.size(1),\n",
    "            img_tensor.size(1),\n",
    "            img_tensor.size(2),\n",
    "        )\n",
    "        img_tensor = torch.cat([img_tensor.unsqueeze(0), z_real], 1)\n",
    "    else:\n",
    "        img_tensor = img_tensor.unsqueeze(0)\n",
    "\n",
    "    # run through model\n",
    "    out_tensor = model(img_tensor)[0].detach()\n",
    "\n",
    "    # post-processing\n",
    "    out_img = out_tensor.data.cpu().float().numpy()\n",
    "    out_img = (np.transpose(out_img, (1, 2, 0)) + 1) / 2.0 * 255.0\n",
    "    # print(out_img)\n",
    "    out_img = cv2.cvtColor(out_img, cv2.COLOR_RGB2BGR)\n",
    "    out_img = cv2.resize(out_img, (orig_width, orig_height), interpolation=cv2.INTER_CUBIC)\n",
    "    if CONCAT:\n",
    "        out_img = np.concatenate((img_orig, out_img), axis=1)\n",
    "    out_image_filepath = Path(DESTINATION_DIRPATH) / image_filepath.name\n",
    "    out_image_filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "    cv2.imwrite(out_image_filepath.as_posix(), out_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joligen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
